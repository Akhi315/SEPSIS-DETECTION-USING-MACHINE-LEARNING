import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# ==============================
# 1. Load Dataset
# ==============================
data_path = "synthetic_sepsis_esp32.csv"
df = pd.read_csv(data_path)
import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import os

# ==============================
# 1. Load & Prepare Dataset
# ==============================
data_path = "synthetic_sepsis_esp32.csv"
df = pd.read_csv(data_path)

# Ensure correct target column
if 'Sepsis_Label' not in df.columns:
    raise ValueError("‚ùå 'Sepsis_Label' column not found in dataset!")

# Encode 'Sex' column (Male=1, Female=0)
if 'Sex' in df.columns:
    df['Sex'] = df['Sex'].map({'Male': 1, 'Female': 0})

# Drop rows with missing values after mapping (just in case)
df = df.dropna()

# Separate features and target
X = df.drop(columns=['Sepsis_Label'])
y = df['Sepsis_Label']

# ==============================
# 2. Split Data
# ==============================
X = df.drop(columns=['Sepsis_Label'])
y = df['Sepsis_Label']

# Split dataset (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==============================
# 3. Define Models
# ==============================
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "SVM": SVC(kernel='rbf', probability=True, random_state=42)
}

# ==============================
# 4. Train & Save Models
# ==============================
for name, model in models.items():
    print(f"üîπ Training {name}...")
    model.fit(X_train_scaled, y_train)
    preds = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, preds)
    print(f"‚úÖ {name} Accuracy: {acc * 100:.2f}%")

    # Save model
    file_name = f"{name.replace(' ', '_')}_model.pkl"
    with open(file_name, "wb") as f:
        pickle.dump(model, f)

    size_kb = os.path.getsize(file_name) / 1024
    print(f"üíæ Saved {file_name} ({size_kb:.0f} KB)")

print("\nüéØ All models trained and saved successfully!\n")

# ==============================
# 5. Save Scaler (important for Flask)
# ==============================
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

print("üß† Scaler saved as scaler.pkl")

# Check if 'Sepsis' column exists (your target variable)
if 'Sepsis_Label' not in df.columns:
    raise ValueError("‚ùå 'Sepsis_Label' column not found in dataset!")

# ==============================
# 2. Split Data
# ==============================
X = df.drop(columns=['Sepsis_Label'])
y = df['Sepsis_Label']


# Split dataset (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==============================
# 3. Define Models
# ==============================
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "SVM": SVC(kernel='rbf', probability=True, random_state=42)
}

# ==============================
# 4. Train & Save Models
# ==============================
for name, model in models.items():
    print(f"üîπ Training {name}...")
    model.fit(X_train_scaled, y_train)
    preds = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, preds)
    print(f"‚úÖ {name} Accuracy: {acc * 100:.2f}%")

    # Save model safely
    file_name = f"{name.replace(' ', '_')}_model.pkl"
    with open(file_name, "wb") as f:
        pickle.dump(model, f)

print("\nüéØ All models trained and saved successfully!\n")

# ==============================
# 5. Save Scaler (important for Flask)
# ==============================
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

print("üß† Scaler saved as scaler.pkl")
